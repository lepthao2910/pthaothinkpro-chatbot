import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from langchain.memory import ConversationSummaryMemory
from langchain_core.output_parsers import StrOutputParser
from langchain.agents import initialize_agent, Tool, AgentType
from langchain_community.tools import DuckDuckGoSearchResults
from langchain_core.documents import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.runnables import RunnablePassthrough
import requests
from bs4 import BeautifulSoup
import pandas as pd
import json
import re

OPENROUTER_API_KEY = "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"

df = pd.read_excel("./ThinkPro_FAQ.xlsx")

documents = []
for index, row in df.iterrows():
    combined_text = f"C√¢u h·ªèi: {row['questions']} Tr·∫£ l·ªùi: {row['anwers']}"
    documents.append(combined_text)

llm = ChatOpenAI(
    api_key=OPENROUTER_API_KEY,
    model="openai/gpt-3.5-turbo",
    base_url="https://openrouter.ai/api/v1",
    default_headers={
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "HTTP-Referer": "http://localhost:8501",
        "X-Title": "ThinkPro Chatbot"
    }
)
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

langchain_documents = [Document(page_content=doc) for doc in documents]

text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
split_documents = text_splitter.split_documents(langchain_documents)

vectorstore = Chroma.from_documents(documents=split_documents, embedding=embeddings, persist_directory="./chroma_db")
vectorstore.persist()
retriever = vectorstore.as_retriever(search_kwargs={"k": 3})

summary_prompt_template = """<s><|user|>Summarize the conversations and update with the new lines.

Current summary:
{summary}

New lines of conversation:
{new_lines}

New summary:<|end|>
<|assistant|>"""

keyword_prompt_template = """B·∫°n l√† m·ªôt c√¥ng c·ª• t·∫°o c√¢u truy v·∫•n t√¨m ki·∫øm t·ª´ y√™u c·∫ßu kh√°ch h√†ng v·ªÅ ThinkPro.

ƒê·∫ßu v√†o: {input_text}

Nhi·ªám v·ª•:
1. Ph√¢n lo·∫°i y√™u c·∫ßu: s·∫£n ph·∫©m, c·ª≠a h√†ng, d·ªãch v·ª•, ho·∫∑c th√¥ng tin chung
2. T√≥m t·∫Øt y√™u c·∫ßu th√†nh m·ªôt c√¢u ng·∫Øn g·ªçn
3. Bi·∫øn c√¢u t√≥m t·∫Øt ƒë√≥ th√†nh m·ªôt truy v·∫•n t√¨m ki·∫øm ph√π h·ª£p

Ch·ªâ tr·∫£ v·ªÅ duy nh·∫•t c√¢u truy v·∫•n t√¨m ki·∫øm, kh√¥ng k√®m l·ªùi gi·∫£i th√≠ch.

Truy v·∫•n t√¨m ki·∫øm:"""

response_prompt_template = """B·∫°n l√† m·ªôt tr·ª£ l√Ω t∆∞ v·∫•n kh√°ch h√†ng chuy√™n nghi·ªáp c·ªßa ThinkPro - c·ª≠a h√†ng c√¥ng ngh·ªá uy t√≠n t·∫°i Vi·ªát Nam. 
D·ª±a v√†o th√¥ng tin t·ª´ c∆° s·ªü d·ªØ li·ªáu n·ªôi b·ªô, th√¥ng tin t√¨m ki·∫øm ƒë∆∞·ª£c v√† l·ªãch s·ª≠ tr√≤ chuy·ªán, h√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa kh√°ch h√†ng v·ªÅ ThinkPro.

TH√îNG TIN C∆† B·∫¢N V·ªÄ THINKPRO:
- ThinkPro l√† h·ªá th·ªëng b√°n l·∫ª c√°c s·∫£n ph·∫©m c√¥ng ngh·ªá ch√≠nh h√£ng t·∫°i Vi·ªát Nam
- Chuy√™n cung c·∫•p laptop, linh ki·ªán m√°y t√≠nh, thi·∫øt b·ªã vƒÉn ph√≤ng, thi·∫øt b·ªã ch∆°i game
- C√≥ c√°c chi nh√°nh t·∫°i H√† N·ªôi v√† TP.HCM
- N·ªïi ti·∫øng v·ªõi d·ªãch v·ª• h·∫≠u m√£i v√† b·∫£o h√†nh uy t√≠n

TH√îNG TIN T·ª™ C∆† S·ªû D·ªÆ LI·ªÜU N·ªòI B·ªò (FAQ):
{rag_context}

TH√îNG TIN C·ª¨A H√ÄNG:
{store_info}

TH√îNG TIN T√åM KI·∫æM ƒê∆Ø·ª¢C T·ª™ INTERNET:
{search_results}

L·ªãch s·ª≠ tr√≤ chuy·ªán:
{chat_history}

C√¢u h·ªèi c·ªßa kh√°ch h√†ng: {input_text}

H∆Ø·ªöNG D·∫™N TR·∫¢ L·ªúI:
1. ∆Øu ti√™n s·ª≠ d·ª•ng th√¥ng tin t·ª´ c∆° s·ªü d·ªØ li·ªáu n·ªôi b·ªô tr∆∞·ªõc
2. N·∫øu kh√¥ng c√≥ th√¥ng tin trong c∆° s·ªü d·ªØ li·ªáu, s·ª≠ d·ª•ng th√¥ng tin t·ª´ internet
3. ƒê·ªëi v·ªõi c√¢u h·ªèi v·ªÅ c·ª≠a h√†ng: s·ª≠ d·ª•ng th√¥ng tin c·ª≠a h√†ng c√≥ s·∫µn
4. Tr·∫£ l·ªùi th√¢n thi·ªán, chuy√™n nghi·ªáp nh∆∞ m·ªôt nh√¢n vi√™n t∆∞ v·∫•n c·ªßa ThinkPro
5. N·∫øu kh√¥ng t√¨m th·∫•y th√¥ng tin, h√£y ƒë·ªÅ ngh·ªã kh√°ch h√†ng li√™n h·ªá tr·ª±c ti·∫øp
6. Lu√¥n gi·ªØ th√°i ƒë·ªô t√≠ch c·ª±c v·ªÅ th∆∞∆°ng hi·ªáu ThinkPro

C√¢u tr·∫£ l·ªùi:"""

rag_template = """S·ª≠ d·ª•ng c√°c ƒëo·∫°n th√¥ng tin sau ƒë√¢y t·ª´ c∆° s·ªü d·ªØ li·ªáu FAQ c·ªßa ThinkPro ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi:

{context}

C√¢u h·ªèi: {question}

Th√¥ng tin li√™n quan:"""

summary_prompt = PromptTemplate(
    input_variables=["new_lines", "summary"],
    template=summary_prompt_template
)

keyword_prompt = PromptTemplate(
    template=keyword_prompt_template,
    input_variables=["input_text"]
)

response_prompt = PromptTemplate(
    template=response_prompt_template,
    input_variables=["chat_history", "search_results", "input_text", "store_info", "rag_context"]
)

rag_prompt = PromptTemplate(
    template=rag_template,
    input_variables=["context","question"]
)

keyword_chain = LLMChain(
    prompt=keyword_prompt,
    llm=llm,
    output_parser=StrOutputParser()
)

rag_chain = (
    {"context": retriever, "question": RunnablePassthrough()}
    | rag_prompt
    | llm
    | StrOutputParser()
)

response_chain = LLMChain(
    prompt=response_prompt,
    llm=llm,
    output_parser=StrOutputParser()
)

THINKPRO_STORE_INFO = """
H·ªÜ TH·ªêNG C·ª¨A H√ÄNG THINKPRO:

üìç H√Ä N·ªòI:
1. ThinkPro D·ªãch V·ªçng H·∫≠u
   - ƒê·ªãa ch·ªâ: 86 D·ªãch V·ªçng H·∫≠u, C·∫ßu Gi·∫•y, H√† N·ªôi
   - Gi·ªù m·ªü c·ª≠a: 8:30 - 22:00 (Th·ª© 2 - Ch·ªß nh·∫≠t)
   - Hotline: 090 483 8888

2. ThinkPro Tr·∫ßn ƒê·∫°i Nghƒ©a
   - ƒê·ªãa ch·ªâ: 116 Tr·∫ßn ƒê·∫°i Nghƒ©a, B√°ch Khoa, Hai B√† Tr∆∞ng, H√† N·ªôi
   - Gi·ªù m·ªü c·ª≠a: 8:30 - 22:00 (Th·ª© 2 - Ch·ªß nh·∫≠t)
   - Hotline: 096 120 2020

üìç TP.HCM:
1. ThinkPro Nguy·ªÖn ƒê√¨nh Chi·ªÉu
   - ƒê·ªãa ch·ªâ: 76 Nguy·ªÖn ƒê√¨nh Chi·ªÉu, ƒêa Kao, Qu·∫≠n 1, TP.HCM
   - Gi·ªù m·ªü c·ª≠a: 8:30 - 22:00 (Th·ª© 2 - Ch·ªß nh·∫≠t)
   - Hotline: 093 889 2020

2. ThinkPro T√¥ Hi·∫øn Th√†nh
   - ƒê·ªãa ch·ªâ: 115 T√¥ Hi·∫øn Th√†nh, P.13, Qu·∫≠n 10, TP.HCM
   - Gi·ªù m·ªü c·ª≠a: 8:30 - 22:00 (Th·ª© 2 - Ch·ªß nh·∫≠t)
   - Hotline: 096 120 2020

D·ªäCH V·ª§:
- Giao h√†ng to√†n qu·ªëc
- B·∫£o h√†nh ch√≠nh h√£ng
- Tr·∫£ g√≥p 0% l√£i su·∫•t
- H·ªó tr·ª£ k·ªπ thu·∫≠t 24/7
- ƒê·ªïi tr·∫£ trong 7 ng√†y
"""

def thinkpro_search(query, max_results=5):
    try:
        query_with_thinkpro = f"{query} site:thinkpro.vn OR site:thinkpro.io OR ThinkPro"
        
        search = DuckDuckGoSearchResults(max_results=max_results)
        results = search.run(query_with_thinkpro)
        
        return results
    except Exception as e:
        return f"L·ªói khi t√¨m ki·∫øm: {str(e)}"

tools = [
    Tool(
        name="ThinkPro Search",
        func=thinkpro_search,
        description="D√πng ƒë·ªÉ t√¨m ki·∫øm th√¥ng tin v·ªÅ ThinkPro tr√™n internet"
    )
]

search_agent = initialize_agent(
    tools=tools,
    llm=llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=False,
    handle_parsing_errors=True
)

st.set_page_config(page_title="ThinkPro Assistant", page_icon="üíª", layout="wide")
st.title("üíª ThinkPro Assistant")
st.markdown("Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi tr·ª£ l√Ω ·∫£o c·ªßa ThinkPro! T√¥i c√≥ th·ªÉ gi√∫p b·∫°n t√¨m th√¥ng tin v·ªÅ s·∫£n ph·∫©m v√† c·ª≠a h√†ng ThinkPro.")

with st.sidebar:
    st.image("https://via.placeholder.com/200x60/000000/FFFFFF/?text=ThinkPro", width=200)
    st.header("ThinkPro Information")
    st.info("""
    **ThinkPro - H·ªá th·ªëng b√°n l·∫ª c√¥ng ngh·ªá ch√≠nh h√£ng**
    - üìç Multiple locations in H√† N·ªôi & TP.HCM
    - üìû Hotline: 1900 63 69 10
    - üåê Website: https://thinkpro.vn
    - ‚è∞ Gi·ªù m·ªü c·ª≠a: 8:30 - 22:00 h√†ng ng√†y
    """)
    
    st.divider()
    st.subheader("H·ªèi v·ªÅ")
    st.write("""
    - üîç S·∫£n ph·∫©m (laptop, linh ki·ªán, thi·∫øt b·ªã)
    - üè™ C·ª≠a h√†ng (ƒë·ªãa ch·ªâ, gi·ªù m·ªü c·ª≠a)
    - üõí D·ªãch v·ª• (b·∫£o h√†nh, giao h√†ng, tr·∫£ g√≥p)
    - üí∞ Khuy·∫øn m√£i, gi√° c·∫£
    - ‚ùì Th√¥ng tin chung v·ªÅ ThinkPro
    """)

if "memory" not in st.session_state:
    st.session_state.memory = ConversationSummaryMemory(
        llm=llm,
        memory_key="chat_history",
        prompt=summary_prompt,
        return_messages=True
    )

if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.messages.append({
        "role": "assistant", 
        "content": "Xin ch√†o! T√¥i l√† tr·ª£ l√Ω ·∫£o c·ªßa ThinkPro. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n t√¨m th√¥ng tin v·ªÅ s·∫£n ph·∫©m c√¥ng ngh·ªá v√† c·ª≠a h√†ng ThinkPro. B·∫°n mu·ªën h·ªèi v·ªÅ s·∫£n ph·∫©m hay th√¥ng tin c·ª≠a h√†ngÂë¢?"
    })

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if user_input := st.chat_input("Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ ThinkPro..."):
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # L·∫•y th√¥ng tin t·ª´ RAG (c∆° s·ªü d·ªØ li·ªáu n·ªôi b·ªô)
    with st.spinner("üîç ƒêang t√¨m ki·∫øm trong c∆° s·ªü d·ªØ li·ªáu FAQ..."):
        rag_context = rag_chain.invoke(user_input)
    
    store_keywords = ["ƒë·ªãa ch·ªâ", "c·ª≠a h√†ng", "chi nh√°nh", "gi·ªù m·ªü c·ª≠a", "li√™n h·ªá", "hotline", "address", "store", "location"]
    is_store_query = any(keyword in user_input.lower() for keyword in store_keywords)
    
    search_results = ""
    if not is_store_query:
        with st.spinner("üåê ƒêang t·∫°o truy v·∫•n t√¨m ki·∫øm..."):
            search_query = keyword_chain.run(input_text=user_input)
        
        with st.spinner("üåê ƒêang t√¨m ki·∫øm th√¥ng tin tr√™n internet..."):
            search_results = search_agent.run(search_query)
    else:
        search_results = "C√¢u h·ªèi v·ªÅ th√¥ng tin c·ª≠a h√†ng - s·ª≠ d·ª•ng d·ªØ li·ªáu c√≥ s·∫µn"
    
    chat_history = st.session_state.memory.load_memory_variables({})["chat_history"]
    
    with st.spinner("üí≠ ƒêang t·∫°o ph·∫£n h·ªìi..."):
        response = response_chain.run(
            chat_history=chat_history,
            search_results=search_results,
            input_text=user_input,
            store_info=THINKPRO_STORE_INFO,
            rag_context=rag_context
        )
    
    st.session_state.memory.save_context(
        {"input": user_input},
        {"output": response}
    )
    
    st.session_state.messages.append({"role": "assistant", "content": response})
    with st.chat_message("assistant"):
        st.markdown(response)
        
    with st.expander("üìä Xem th√¥ng tin chi ti·∫øt"):
        st.write(f"**Truy v·∫•n t√¨m ki·∫øm:** {search_query if not is_store_query else 'C√¢u h·ªèi v·ªÅ c·ª≠a h√†ng'}")
        st.write("**Th√¥ng tin t·ª´ c∆° s·ªü d·ªØ li·ªáu FAQ:**")
        st.info(rag_context)
        if not is_store_query:
            st.write("**K·∫øt qu·∫£ t√¨m ki·∫øm internet:**")
            st.info(search_results)
        else:
            st.info("S·ª≠ d·ª•ng th√¥ng tin c·ª≠a h√†ng c√≥ s·∫µn")


st.divider()

